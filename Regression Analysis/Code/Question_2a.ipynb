{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Question_2a.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"uUDCwXQDzR6E","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn import preprocessing\n","from sklearn import linear_model\n","from sklearn.linear_model import Ridge, Lasso, ElasticNet\n","from sklearn.model_selection import cross_val_predict, cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn import metrics  as metrics\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import cross_validate\n","from scipy.sparse import csr_matrix\n","\n","from sklearn.feature_selection import f_regression, mutual_info_regression\n","\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_P83kPLtzR6Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["df1 = pd.read_csv('network_backup_dataset.csv',delimiter=',', header=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lSbZkBgezR6X","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"ds9Cj17PzR6e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"475f081b-01eb-463c-9e95-e3d2acc4f154"},"cell_type":"code","source":["# Scalar Encoding\n","le = preprocessing.LabelEncoder()\n","\n","row=df1.shape[0]\n","col=df1.shape[1]\n","\n","df = df1\n","\n","# Scalar Encoding of the 3 categorical values\n","le.fit(df.iloc[0:row,1])\n","df.iloc[0:row,1]= le.transform(df1.iloc[0:row,1])\n","\n","le.fit(df.iloc[0:row,3])\n","df.iloc[0:row,3]= le.transform(df1.iloc[0:row,3])\n","\n","le.fit(df.iloc[0:row,4])\n","df.iloc[0:row,4]= le.transform(df1.iloc[0:row,4])\n","    \n","X = df.iloc[0:row,0:5]\n","\n","y = df1.iloc[0:row, 5]\n","\n","lr = linear_model.LinearRegression()\n","\n","scores = cross_validate(lr, X, y,scoring='neg_mean_squared_error',cv=10)\n","\n","print('Simple Regression with scalar encoding')\n","test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","print('Test RMSE',test_rmse)\n","print('Train RMSE',train_rmse)\n","\n","# Plot of actual vs fitted values\n","\n","y_predicted = cross_val_predict(lr, X, y, cv=10)\n","\n","\n","fig, ax = plt.subplots()\n","ax.scatter(x=y, y=y_predicted,color='g',marker='o',s=0.25)\n","ax.plot([0, y.max()], [y.min(), y.max()],  'k--', lw=4)\n","ax.set_xlabel('Actual')\n","ax.set_ylabel('Fitted')\n","plt.title('Actual vs Fitted Values')\n","plt.savefig('Actual vs Fitted Values')\n","plt.show()\n","\n","\n","# Plot of Fitted vs Residual values\n","y_residual = y - y_predicted\n","fig, ax = plt.subplots()\n","ax.scatter(y_predicted, y_residual,color='g',marker='o',s=0.25)\n","ax.set_xlabel('Fitted')\n","ax.set_ylabel('Residual')\n","plt.title('Fitted vs Residual Values')\n","plt.savefig('Fitted vs Residual Values')\n","plt.show()\n","\n","datapoints = range(row)\n","\n","# Plot of actual and fitted values\n","fig, ax = plt.subplots()\n","a=ax.scatter(datapoints, y,color='r',marker='o',s=0.25)\n","b=ax.scatter(datapoints, y_predicted,color='g',marker='o',s=0.25)\n","ax.plot([0, y.max()], [y.min(), y.max()],  'k--', lw=4)\n","ax.set_xlabel('Data Points')\n","ax.set_ylabel('Actual and Fitted values')\n","plt.title('Actual and Fitted Values')\n","ax.legend((a,b),('Actual','Fitted'))\n","plt.savefig('Actual and Fitted values')\n","plt.show()\n","\n","\n","# Plot of Fitted and Residual values\n","y_residual = y - y_predicted\n","fig, ax = plt.subplots()\n","a=ax.scatter(datapoints, y_residual,color='r',marker='o',s=0.25)\n","b=ax.scatter(datapoints, y_predicted,color='g',marker='o',s=0.25)\n","ax.set_xlabel('Data Points')\n","ax.set_ylabel('Residual and Fitted values ')\n","plt.title('Fitted and Residual Values')\n","ax.legend((a,b),('Residual','Fitted'))\n","plt.savefig('Fitted and Residual Values')\n","plt.show()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Simple Regression with scalar encoding\n","('Test RMSE', 0.10193944624209859)\n","('Train RMSE', 0.10183435819796752)\n"],"name":"stdout"}]},{"metadata":{"id":"1ROpelb6zR6m","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"aa7b8a97-64c0-4b96-ab02-bbe8d9f95235"},"cell_type":"code","source":["# Standardization\n","\n","lr = linear_model.LinearRegression()\n","scaler = StandardScaler()\n","data = X\n","\n","\n","scaler.fit(data)\n","standardized_data = scaler.transform(data)\n","\n","scores = cross_validate(lr, standardized_data, y,scoring='neg_mean_squared_error',cv=10)\n","test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","\n","print('After Standardization')\n","print('Test RMSE',test_rmse)\n","print('Train RMSE',train_rmse)\n","\n","predicted = cross_val_predict(lr, standardized_data, y, cv=10)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["After Standardization\n","('Test RMSE', 0.10193944624209859)\n","('Train RMSE', 0.10183435819796753)\n"],"name":"stdout"}]},{"metadata":{"id":"hq7q7hPEzR6u","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"88b312ca-f15e-4409-c1ca-4fbd839141d9"},"cell_type":"code","source":["# Selecting Features\n","\n","f_test, _ = f_regression(data, y)\n","f_test /= np.max(f_test)\n","\n","mi = mutual_info_regression(data, y)\n","mi /= np.max(mi)\n","\n","print('Selecting 3 best features from f_regression')\n","print('f_regression')\n","print(f_test)\n","\n","print('Selecting 3 best features from Mutual Information')\n","print('mutual information')\n","print(mi)\n","\n","\n","X_reduced = X.iloc[0:row, [False,True,True,False,True]]\n","        \n","scores = cross_validate(lr,X_reduced,y,scoring='neg_mean_squared_error',cv=10)\n","test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","print('Test RMSE after selecting 3 best features using f_regression ',test_rmse)\n","print('Train RMSE',train_rmse)\n","\n","# Plot of actual vs fitted values\n","\n","y_predicted = cross_val_predict(lr, X_reduced, y, cv=10)\n","\n","fig, ax = plt.subplots()\n","ax.scatter(x=y, y=y_predicted,color='g',marker='o',s=0.25)\n","ax.plot([0, y.max()], [y.min(), y.max()],  'k--', lw=4)\n","ax.set_xlabel('Actual')\n","ax.set_ylabel('Fitted')\n","plt.title('Actual vs Fitted Values')\n","plt.savefig('After Feature Selection: Actual vs Fitted Values')\n","plt.show()\n","\n","\n","# Plot of Fitted vs Residual values\n","y_residual = y - y_predicted\n","fig, ax = plt.subplots()\n","ax.scatter(y_predicted, y_residual,color='g',marker='o',s=0.25)\n","ax.set_xlabel('Fitted')\n","ax.set_ylabel('Residual')\n","plt.title('Fitted vs Residual Values')\n","plt.savefig('After Feature Selection: Fitted vs Residual Values')\n","plt.show()\n","\n","datapoints = range(row)\n","# Plot of actual and fitted values\n","fig, ax = plt.subplots()\n","a=ax.scatter(datapoints, y,color='r',marker='o',s=0.25)\n","b=ax.scatter(datapoints, y_predicted,color='g',marker='o',s=0.25)\n","ax.plot([0, y.max()], [y.min(), y.max()],  'k--', lw=4)\n","ax.set_xlabel('Data Points')\n","ax.set_ylabel('Actual and Fitted values')\n","plt.title('After Feature Selection: Actual and Fitted Values')\n","ax.legend((a,b),('Actual','Fitted'))\n","plt.savefig('After Feature Selection: Actual and Fitted values')\n","plt.show()\n","\n","\n","# Plot of Fitted and Residual values\n","y_residual = y - y_predicted\n","fig, ax = plt.subplots()\n","a=ax.scatter(datapoints, y_residual,color='r',marker='o',s=0.25)\n","b=ax.scatter(datapoints, y_predicted,color='g',marker='o',s=0.25)\n","ax.set_xlabel('Data Points')\n","ax.set_ylabel('Residual and Fitted values ')\n","plt.title('After Feature Selection: Fitted and Residual Values')\n","ax.legend((a,b),('Residual','Fitted'))\n","plt.savefig('After Feature Selection: Fitted and Residual Values')\n","plt.show()\n","\n","\n","X_reduced = X.iloc[0:row, [False,False,True,True,True]]\n","        \n","scores = cross_validate(lr,X_reduced,y,scoring='neg_mean_squared_error',cv=10)\n","test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","print('Test RMSE after selecting 3 best features using nutual information' ,test_rmse)\n","print('Train RMSE',train_rmse)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Selecting 3 best features from f_regression\n","f_regression\n","[  1.83383477e-05   4.78772999e-01   3.27138366e-01   5.67261995e-02\n","   1.00000000e+00]\n","Selecting 3 best features from Mutual Information\n","mutual information\n","[ 0.00414402  0.45521467  0.62228067  0.7461687   1.        ]\n","('Test RMSE after selecting 3 best features using f_regression ', 0.1018934267654872)\n","('Train RMSE', 0.10187197479409449)\n","('Test RMSE after selecting 3 best features using nutual information', 0.10254728677099285)\n","('Train RMSE', 0.10246541286731993)\n"],"name":"stdout"}]},{"metadata":{"id":"VEVliKCvzR6z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"5e7fa3d6-e316-4bea-c663-0be74f17d357"},"cell_type":"code","source":["# One hot encoding\n","\n","test_rmse_enc = [0]*32\n","train_rmse_enc = [0]*32\n","\n","super_X = []\n","            \n","\n","for i in range(0,32):\n","    \n","    b = \"{0:05b}\".format(i)\n","\n","    b = list(b)\n","    value = []\n","    for x in b:\n","        if x=='0':\n","            value.append(False)\n","        else:\n","            value.append(True)\n","    enc = OneHotEncoder(categorical_features=value)\n","    enc.fit(X)\n","    X_encoded = enc.transform(X)\n","    \n","    if i!=0:\n","        X_encoded = X_encoded.todense()\n","        \n","    super_X.append(X_encoded)\n","    \n","    \n","    scores = cross_validate(lr,X_encoded,y,scoring='neg_mean_squared_error',cv=10)\n","    test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","    train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","    test_rmse_enc[i] = test_rmse\n","    train_rmse_enc[i] = train_rmse\n","    \n","print('Test RMSE of the 32 models') \n","print(test_rmse_enc)\n","print('Minimum Test RMSE',min(test_rmse_enc))\n","print('Train RMSE of the 32 models')\n","print(train_rmse_enc)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test RMSE of the 32 models\n","[0.10193944624209859, 0.090968244789234071, 0.090965435745335804, 0.090967777891921967, 0.1007047686560026, 0.089573220589374003, 0.089574171641399442, 0.089584844887701701, 0.1009757241245799, 0.089910883168603975, 0.089908188253164198, 0.089920089156094091, 0.099738534894066852, 0.088507099324723421, 0.088507360144404648, 0.088508373687921721, 8065370829.5817604, 17461609275.458393, 15615450317.490131, 26896548047.500687, 7001681485.6499958, 36800500816.852264, 22583523876.873058, 109184256519.27597, 13148003254.87126, 17207308281.642895, 19447376948.255455, 52596226886.327904, 23400956820.067589, 245424233914.4487, 18502358572.67556, 555674402231.9502]\n","('Minimum Test RMSE', 0.088507099324723421)\n","Train RMSE of the 32 models\n","[0.10183435819796752, 0.090793594435595593, 0.090796238285714856, 0.090793626996754584, 0.10058577720887095, 0.089385277370006191, 0.089386331588134707, 0.089385689070760124, 0.10088992814449357, 0.089758534916399665, 0.089758188931314264, 0.089758870079687775, 0.099637685671444709, 0.088338505839689607, 0.088339889994547352, 0.08834013560010659, 0.10182832364470487, 0.090787811865523385, 0.090789528399592756, 0.090787165405974535, 0.10057945858835408, 0.08937824464040843, 0.089379496546441534, 0.089392972368840057, 0.10088738931541147, 0.089753728608563621, 0.089755368318915452, 0.089754490107035734, 0.099634661654162071, 0.088342175774585169, 0.088337748757025519, 0.088368971131411705]\n"],"name":"stdout"}]},{"metadata":{"id":"YUKUVibfzR63","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}]},"outputId":"ef9ddb27-a670-46c9-b237-295d4a27094c"},"cell_type":"code","source":["# Large difference in Train and Test error is observed when all the features are vector encoded\n","\n","# We try to improve the results by regularization\n","\n","# We optimize the parameters for the best model i.e the one with first parameter scalar encoded and the rest vector encoded\n","\n","X_chosen = super_X[16]\n","\n","print('Ridge Regularizer')\n","al = [0.1,0.2,0.5,1,2,4,8,16,20,24,28,32,36,40,44,48,60,80,100]\n","\n","test_rmse_ridge = []\n","\n","for a in al:\n","\n","    ridge = Ridge(alpha=a)\n","    lr_ridge = ridge.fit(X_chosen, y)\n","\n","    scores = cross_validate(lr_ridge,X_chosen,y,scoring='neg_mean_squared_error',cv=10)\n","    test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","    train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","\n","    test_rmse_ridge.append(test_rmse)\n","    print(test_rmse,'alpha=',a)\n","    \n","plt.plot(al,test_rmse_ridge,'x',linestyle='-')\n","plt.xlabel('Alpha value')\n","plt.ylabel('Test RMSE ')\n","plt.title('Test RMS value vs alpha using Ridge Regularization')\n","plt.show()\n","plt.savefig('Test RMS value vs alpha using Ridge Regularization')\n","\n","\n","\n","print('Lasso Regularizer')\n","al = [0.001,0.002,0.003,0.004,0.005]\n","\n","test_rmse_lasso = []\n","\n","for a in al:\n","    lasso = Lasso(alpha=a)\n","    lr_lasso = lasso.fit(X_chosen, y)\n","\n","    scores = cross_validate(lr_lasso,X_chosen,y,scoring='neg_mean_squared_error',cv=10)\n","    test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","    train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","\n","    print(test_rmse, 'alpha=', a)\n","  \n","    test_rmse_lasso.append(test_rmse)\n","    \n","plt.plot(al,test_rmse_lasso,'x',linestyle='-')\n","plt.xlabel('Alpha value')\n","plt.ylabel('Test RMSE ')\n","plt.title('Test RMS value vs alpha using Lasso Regularization')\n","plt.show()\n","plt.savefig('Test RMS value vs alpha using Lasso Regularization')\n","\n","print('Elastic Net Regression')\n","\n","l = [0,0.01,0.02,0.03,0.04,0.05,0.06,0.07]\n","\n","test_rmse_elastic = []\n","for r in l:\n","\n","    elasticNet = ElasticNet(alpha=.001, l1_ratio=r, random_state=0)\n","    lr_elastic = elasticNet.fit(X_chosen, y)\n","\n","    scores = cross_validate(lr_elastic,X_encoded,y,scoring='neg_mean_squared_error',cv=10)\n","    test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","    train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","\n","    print('Test RMSE',test_rmse)\n","    print('Train RMSE',train_rmse)\n","    test_rmse_elastic.append(test_rmse)\n","    \n","# Best model \n","# Best value seems to be alpha = 0.001 and l1_ratio=0.04\n","\n","elasticNet = ElasticNet(alpha=.001, l1_ratio=0.04, random_state=0)\n","lr_elastic = elasticNet.fit(X_chosen, y)\n","y_predicted = cross_val_predict(lr_elastic, X_chosen, y, cv=10)   \n","scores = cross_validate(lr_elastic,X_encoded,y,scoring='neg_mean_squared_error',cv=10)\n","test_rmse = np.sqrt(np.mean(np.abs(scores['test_score'])))\n","train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","\n","print(test_rmse)\n","print(train_rmse)\n","\n","plt.plot(l,test_rmse_elastic,'x',linestyle='-')\n","plt.xlabel('L1 ratio')\n","plt.ylabel('Test RMSE ')\n","plt.title('Test RMS value vs l1 ratio using Elastic Net Regularization')\n","plt.show()\n","plt.savefig('Test RMS value vs l1 ratio using Elastic Net Regularization')   \n","\n","\n","\n","\n","datapoints = range(row)\n","# Plot of actual and fitted values\n","fig, ax = plt.subplots()\n","a=ax.scatter(datapoints, y,color='r',marker='o',s=0.25)\n","b=ax.scatter(datapoints, y_predicted,color='g',marker='o',s=0.25)\n","ax.plot([0, y.max()], [y.min(), y.max()],  'k--', lw=4)\n","ax.set_xlabel('Data Points')\n","ax.set_ylabel('Actual and Fitted values')\n","plt.title('Best Model: Actual and Fitted Values')\n","ax.legend((a,b),('Actual','Fitted'))\n","plt.savefig('Best Model: Actual and Fitted values')\n","plt.show()\n","\n","\n","# Plot of Fitted and Residual values\n","y_residual = y - y_predicted\n","fig, ax = plt.subplots()\n","a=ax.scatter(datapoints, y_residual,color='r',marker='o',s=0.25)\n","b=ax.scatter(datapoints, y_predicted,color='g',marker='o',s=0.25)\n","ax.set_xlabel('Data Points')\n","ax.set_ylabel('Residual and Fitted values ')\n","plt.title('Best Model: Fitted and Residual Values')\n","ax.legend((a,b),('Residual','Fitted'))\n","plt.savefig('Best Model: Fitted and Residual Values')\n","plt.show()\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Ridge Regularizer\n","(0.10851836822962944, 'alpha=', 0.1)\n","(0.1075738201990262, 'alpha=', 0.2)\n","(0.10571574017401884, 'alpha=', 0.5)\n","(0.10419401459286225, 'alpha=', 1)\n","(0.10305106183058908, 'alpha=', 2)\n","(0.10243776629898954, 'alpha=', 4)\n","(0.10218846954135967, 'alpha=', 8)\n","(0.10210308285123543, 'alpha=', 16)\n","(0.10209037500930061, 'alpha=', 20)\n","(0.10208266393855286, 'alpha=', 24)\n","(0.10207743964450718, 'alpha=', 28)\n","(0.10207359927009213, 'alpha=', 32)\n","(0.1020705951089065, 'alpha=', 36)\n","(0.10206812942950977, 'alpha=', 40)\n","(0.10206602870644642, 'alpha=', 44)\n","(0.10206418603171387, 'alpha=', 48)\n","(0.1020596224038189, 'alpha=', 60)\n","(0.10205367644291624, 'alpha=', 80)\n","(0.10204872771630495, 'alpha=', 100)\n","Lasso Regularizer\n","(0.10193834069233614, 'alpha=', 0.001)\n","(0.10194992688185092, 'alpha=', 0.002)\n","(0.10194842622436756, 'alpha=', 0.003)\n","(0.10193610187392778, 'alpha=', 0.004)\n","(0.10192944490108458, 'alpha=', 0.005)\n","Elastic Net Regression\n","('Test RMSE', 0.088522949070799023)\n","('Train RMSE', 0.08833529931107037)\n","('Test RMSE', 0.088509524016294958)\n","('Train RMSE', 0.088335921108618404)\n","('Test RMSE', 0.088507810838593617)\n","('Train RMSE', 0.088336936340842706)\n","('Test RMSE', 0.088506808808555867)\n","('Train RMSE', 0.088338077497681522)\n","('Test RMSE', 0.088506316827440229)\n","('Train RMSE', 0.08833923300887464)\n","('Test RMSE', 0.088506581634956893)\n","('Train RMSE', 0.088340325197991218)\n","('Test RMSE', 0.088506905532260496)\n","('Train RMSE', 0.088341331813108201)\n","('Test RMSE', 0.088506511037397012)\n","('Train RMSE', 0.088342312119269739)\n","0.0885063168274\n","0.0883392330089\n"],"name":"stdout"}]},{"metadata":{"id":"EpiyQkopzR69","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Ridge Regularization\n","\n","\n","print('Ridge Regularizer')\n","al = [0.1,0.2,0.5,1,2,4,8,16,20,24,28,32,36,40,44,48,60,80,100]\n","\n","test_rmse_ridge = []\n","\n","for a in al:\n","    test_rmse = 0\n","    for X_chosen in super_X:\n","    \n","\n","        ridge = Ridge(alpha=a)\n","        lr_ridge = ridge.fit(X_chosen, y)\n","\n","        scores = cross_validate(lr_ridge,X_chosen,y,scoring='neg_mean_squared_error',cv=10)\n","        test_rmse += np.sqrt(np.mean(np.abs(scores['test_score'])))\n","        train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","\n","    test_rmse_ridge.append(test_rmse/32.0)\n","    print(test_rmse/32.0,a)\n","    \n","plt.plot(al,test_rmse_ridge,'x',linestyle='-')\n","plt.xlabel('Alpha value')\n","plt.ylabel('Average test RMSE value among the 32 models')\n","plt.title('Average test RMS value vs alpha using Ridge Regularization')\n","plt.show()\n","plt.savefig('Average test RMS value vs alpha using Ridge Regularization')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HDM5Uv4CzR6_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{},{}]},"outputId":"9544858e-49f8-49d7-ab60-de7f65b42f4f"},"cell_type":"code","source":["# Lasso Regularization\n","\n","al = [0,0.001,0.002,0.003,0.004,0.005]\n","\n","test_rmse_lasso = []\n","\n","\n","for a in al:\n","    test_rmse = 0\n","    for X_chosen in super_X:\n","    \n","\n","        lasso = Lasso(alpha=a)\n","        lr_lasso = lasso.fit(X_chosen, y)\n","\n","        scores = cross_validate(lr_lasso,X_chosen,y,scoring='neg_mean_squared_error',cv=10)\n","        test_rmse += np.sqrt(np.mean(np.abs(scores['test_score'])))\n","        train_rmse =np.sqrt(np.mean(np.abs(scores['train_score'])))\n","\n","    test_rmse_lasso.append(test_rmse/32.0)\n","    print(test_rmse_lasso/32.0,a)\n","    \n","plt.plot(al,test_rmse_lasso,'x',linestyle='-')\n","plt.xlabel('Alpha value')\n","plt.ylabel('Average test RMSE value among the 32 models')\n","plt.title('Average test RMS value vs alpha using Lasso Regularization')\n","plt.show('Average test RMS value vs alpha using Lasso Regularization')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/home/shreya/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n"],"name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for /: 'list' and 'float'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-19-75351ffe19b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtest_rmse_lasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_rmse\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m32.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_rmse_lasso\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m32.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_rmse_lasso\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'float'"]}]},{"metadata":{"id":"Zj4s2czqzR7E","colab_type":"raw"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"4OP6jHuLzR7F","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AqU8iRDjzR7H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0IpEAH24zR7K","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"FHIc_QY4zR7O","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"YqU7cicTzR7Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","                \n","        \n","            \n","    \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kKNXwCf6zR7U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"-CG7eqrCzR7W","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}